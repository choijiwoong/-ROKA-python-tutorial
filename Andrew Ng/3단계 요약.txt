	[목표 설정하기]
-정확도와 재현율 따로 평가하는 것 보다 둘의 조화평균은 F1-score과 같은 것으로 평가하는 것이 좋고, 데이터 셋과 더불어 하나의 실수 평가기준을 정하는게 좋다.
-최적의 기준을 위해서 가장 중요시하는 기준을 optimizing metrics로 정하고, 그 속에서 최소한의 조건으로서 satisfcing metric을 사용할 수 있다. 여기서 조건척도는 해당 기준을 넘으면 성능에 큰 차이가 없다
 예로는 음성인식의 경우 정확도를 최적척도, 하루에 한번 이상 깨어난다는 것을 조건척도로 삼을 수 있다.
-같은 분포에서 나온 데이터를 사용하는게 중요하며, 미래를 예측하여 확장가능한 데이터 세트를 얻는것이 좋다. 고로 shuffle을 사용하는 이유가 이것이다.
-레이블과의 오차는 적지만 잘못 분류하는 것이 특정 알고리즘에서 치명적이라면 새로운 평가 척도(예를들면 가중항을 적용하여 원하지 않는 결과에 loss를 크게 만들거나)를 도입하는 것이 좋다. 또한 실제 사용하는 데이터를 test, train데이터로 사용하는것도 좋다.(실제와 차이가 날경우)

	[사람 수준의 성능과 비교하기]
-Bayes optimal error는 x에서 y로의 human level performance를 뛰어넘어 이론상 최고의 성능을 의미한다. 
-하지만 과하게 높은 수준은 필요하지 않기에, 베이지안 오차를 사람 수준의 오차라고 가정하고 평가점수를 매긴다.(그 이상은 과적합)
 베이지안 오차와 모델 사이의 오차를 avoidable bias라고 부르며, train error와 dev error를 줄이기 위해서는 normalization, varience(train과 dev의 오차차이)의 조정으로 달성이 가능하다.
-베이즈오차가 성능의 발전 방향 bias조정, varience조정 등에 도움이 되며, 베이즈오차 자체가 원래 큰 경우 원활하지 않은 결과가 나올 수 밖에 없다
-사람수준의성능을 뛰어넘기 위해서는 구조화된 데이터, 방대한 양의 데이터가 필수적이다.

	[오차 분석]